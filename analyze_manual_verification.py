#!/usr/bin/env python3
"""
åˆ†ææ‰‹åŠ¨éªŒè¯ç»“æœ
ä»å¡«å†™å¥½çš„éªŒè¯æ–‡æ¡£ä¸­æå–ç»Ÿè®¡ä¿¡æ¯
"""

import re
from collections import defaultdict

def parse_verification_document(filename="manual_verification_samples.md"):
    """è§£æéªŒè¯æ–‡æ¡£"""
    with open(filename, 'r', encoding='utf-8') as f:
        content = f.read()
    
    results = []
    current_faq = {}
    
    # åŒ¹é…FAQå—
    faq_pattern = r'### FAQ #(\d+) - (é«˜åˆ†|ä¸­åˆ†|ä½åˆ†) \(ä¸€è‡´æ€§åˆ†æ•°: ([\d.]+)\)'
    
    for match in re.finditer(faq_pattern, content):
        faq_num = match.group(1)
        quality_level = match.group(2)
        auto_score = float(match.group(3))
        
        # æå–é—®é¢˜
        question_match = re.search(r'\*\*é—®é¢˜\*\*:\n```\n(.*?)\n```', content[match.end():match.end()+2000], re.DOTALL)
        question = question_match.group(1).strip() if question_match else ""
        
        # æå–ç­”æ¡ˆ
        answer_match = re.search(r'\*\*ç­”æ¡ˆ\*\*:\n```\n(.*?)\n```', content[match.end():match.end()+2000], re.DOTALL)
        answer = answer_match.group(1).strip() if answer_match else ""
        
        # æå–äººå·¥è¯„ä¼°ï¼ˆå¦‚æœå·²å¡«å†™ï¼‰
        accuracy_match = re.search(r'å‡†ç¡®æ€§:.*?\[([xX ])\].*?âœ….*?\[([xX ])\].*?âš ï¸.*?\[([xX ])\].*?âŒ', content[match.end():match.end()+500])
        relevance_match = re.search(r'ç›¸å…³æ€§:.*?\[([xX ])\].*?âœ….*?\[([xX ])\].*?âš ï¸.*?\[([xX ])\].*?âŒ', content[match.end():match.end()+500])
        naturalness_match = re.search(r'è‡ªç„¶åº¦:.*?\[([xX ])\].*?âœ….*?\[([xX ])\].*?âš ï¸.*?\[([xX ])\].*?âŒ', content[match.end():match.end()+500])
        completeness_match = re.search(r'å®Œæ•´æ€§:.*?\[([xX ])\].*?âœ….*?\[([xX ])\].*?âš ï¸.*?\[([xX ])\].*?âŒ', content[match.end():match.end()+500])
        
        # åˆ¤æ–­è¯„ä¼°ç»“æœ
        def get_rating(match_obj):
            if not match_obj:
                return None
            if match_obj.group(1).lower() == 'x':
                return 'high'
            elif match_obj.group(2).lower() == 'x':
                return 'medium'
            elif match_obj.group(3).lower() == 'x':
                return 'low'
            return None
        
        accuracy = get_rating(accuracy_match)
        relevance = get_rating(relevance_match)
        naturalness = get_rating(naturalness_match)
        completeness = get_rating(completeness_match)
        
        # æ£€æŸ¥æ˜¯å¦æœ‰è¡¨è¾¾åå·®æ ‡è®°
        bias_match = re.search(r'ç­”æ¡ˆè¡¨è¾¾æ–¹å¼ä¸åŒä½†æ„æ€ç›¸åŒ.*?\[([xX ])\]', content[match.end():match.end()+1000], re.DOTALL)
        has_expression_bias = bias_match and bias_match.group(1).lower() == 'x'
        
        results.append({
            'faq_num': faq_num,
            'quality_level': quality_level,
            'auto_score': auto_score,
            'question': question[:50] + '...' if len(question) > 50 else question,
            'answer': answer[:50] + '...' if len(answer) > 50 else answer,
            'accuracy': accuracy,
            'relevance': relevance,
            'naturalness': naturalness,
            'completeness': completeness,
            'has_expression_bias': has_expression_bias
        })
    
    return results

def analyze_results(results):
    """åˆ†æéªŒè¯ç»“æœ"""
    total = len(results)
    if total == 0:
        print("âŒ æœªæ‰¾åˆ°éªŒè¯ç»“æœï¼")
        return
    
    # ç»Ÿè®¡å‡†ç¡®æ€§
    accuracy_stats = defaultdict(int)
    for r in results:
        if r['accuracy']:
            accuracy_stats[r['accuracy']] += 1
    
    # ç»Ÿè®¡ç›¸å…³æ€§
    relevance_stats = defaultdict(int)
    for r in results:
        if r['relevance']:
            relevance_stats[r['relevance']] += 1
    
    # ç»Ÿè®¡è‡ªç„¶åº¦
    naturalness_stats = defaultdict(int)
    for r in results:
        if r['naturalness']:
            naturalness_stats[r['naturalness']] += 1
    
    # ç»Ÿè®¡å®Œæ•´æ€§
    completeness_stats = defaultdict(int)
    for r in results:
        if r['completeness']:
            completeness_stats[r['completeness']] += 1
    
    # æŒ‰è‡ªåŠ¨åŒ–è¯„ä¼°åˆ†æ•°åˆ†ç±»
    high_auto = [r for r in results if r['auto_score'] >= 0.7]
    low_auto = [r for r in results if r['auto_score'] < 0.5]
    
    # é«˜è‡ªåŠ¨åŒ–åˆ†æ•°ä¸­ï¼Œäººå·¥è¯„ä¼°ä¸ºå‡†ç¡®çš„æ¯”ä¾‹
    high_auto_accurate = sum(1 for r in high_auto if r['accuracy'] == 'high')
    high_auto_accurate_pct = (high_auto_accurate / len(high_auto) * 100) if high_auto else 0
    
    # ä½è‡ªåŠ¨åŒ–åˆ†æ•°ä¸­ï¼Œäººå·¥è¯„ä¼°ä¸ºå‡†ç¡®çš„æ¯”ä¾‹
    low_auto_accurate = sum(1 for r in low_auto if r['accuracy'] == 'high')
    low_auto_accurate_pct = (low_auto_accurate / len(low_auto) * 100) if low_auto else 0
    
    # è¡¨è¾¾åå·®ç»Ÿè®¡
    expression_bias_count = sum(1 for r in results if r['has_expression_bias'])
    
    # æ‰“å°æŠ¥å‘Š
    print("=" * 80)
    print("ğŸ“Š æ‰‹åŠ¨éªŒè¯ç»“æœåˆ†æ")
    print("=" * 80)
    print()
    print(f"æ€»éªŒè¯æ ·æœ¬æ•°: {total}")
    print()
    
    # å‡†ç¡®æ€§åˆ†å¸ƒ
    print("ğŸ“ˆ å‡†ç¡®æ€§åˆ†å¸ƒ:")
    if accuracy_stats:
        high_count = accuracy_stats.get('high', 0)
        medium_count = accuracy_stats.get('medium', 0)
        low_count = accuracy_stats.get('low', 0)
        total_rated = high_count + medium_count + low_count
        
        if total_rated > 0:
            print(f"  âœ… å‡†ç¡®: {high_count:3d} ({high_count/total_rated*100:5.1f}%)")
            print(f"  âš ï¸  éƒ¨åˆ†å‡†ç¡®: {medium_count:3d} ({medium_count/total_rated*100:5.1f}%)")
            print(f"  âŒ ä¸å‡†ç¡®: {low_count:3d} ({low_count/total_rated*100:5.1f}%)")
        else:
            print("  âš ï¸  å°šæœªå¡«å†™å‡†ç¡®æ€§è¯„ä¼°")
    else:
        print("  âš ï¸  å°šæœªå¡«å†™å‡†ç¡®æ€§è¯„ä¼°")
    print()
    
    # ç›¸å…³æ€§åˆ†å¸ƒ
    print("ğŸ“Š ç›¸å…³æ€§åˆ†å¸ƒ:")
    if relevance_stats:
        high_count = relevance_stats.get('high', 0)
        medium_count = relevance_stats.get('medium', 0)
        low_count = relevance_stats.get('low', 0)
        total_rated = high_count + medium_count + low_count
        
        if total_rated > 0:
            print(f"  âœ… é«˜åº¦ç›¸å…³: {high_count:3d} ({high_count/total_rated*100:5.1f}%)")
            print(f"  âš ï¸  éƒ¨åˆ†ç›¸å…³: {medium_count:3d} ({medium_count/total_rated*100:5.1f}%)")
            print(f"  âŒ ä¸ç›¸å…³: {low_count:3d} ({low_count/total_rated*100:5.1f}%)")
    else:
        print("  âš ï¸  å°šæœªå¡«å†™ç›¸å…³æ€§è¯„ä¼°")
    print()
    
    # ä¸è‡ªåŠ¨åŒ–è¯„ä¼°çš„å¯¹æ¯”
    print("ğŸ” ä¸è‡ªåŠ¨åŒ–è¯„ä¼°çš„å¯¹æ¯”:")
    print(f"  é«˜ä¸€è‡´æ€§åˆ†æ•°ï¼ˆâ‰¥0.7ï¼‰çš„FAQ: {len(high_auto)} ä¸ª")
    if high_auto:
        print(f"    å…¶ä¸­äººå·¥è¯„ä¼°ä¸ºå‡†ç¡®çš„æ¯”ä¾‹: {high_auto_accurate}/{len(high_auto)} ({high_auto_accurate_pct:.1f}%)")
    
    print(f"  ä½ä¸€è‡´æ€§åˆ†æ•°ï¼ˆ<0.5ï¼‰çš„FAQ: {len(low_auto)} ä¸ª")
    if low_auto:
        print(f"    å…¶ä¸­äººå·¥è¯„ä¼°ä¸ºå‡†ç¡®çš„æ¯”ä¾‹: {low_auto_accurate}/{len(low_auto)} ({low_auto_accurate_pct:.1f}%)")
    print()
    
    # è¡¨è¾¾åå·®
    print("âš ï¸  è¡¨è¾¾åå·®ç»Ÿè®¡:")
    print(f"  å‘ç°è¡¨è¾¾åå·®çš„FAQ: {expression_bias_count} ä¸ª ({expression_bias_count/total*100:.1f}%)")
    print(f"  ï¼ˆç­”æ¡ˆæ­£ç¡®ä½†è¡¨è¾¾ä¸åŒï¼Œå¯¼è‡´è‡ªåŠ¨åŒ–è¯„ä¼°åˆ†æ•°åä½ï¼‰")
    print()
    
    # æ€»ä½“ä¸€è‡´æ€§
    if accuracy_stats:
        total_rated = sum(accuracy_stats.values())
        if total_rated > 0:
            # è®¡ç®—è‡ªåŠ¨åŒ–è¯„ä¼°ä¸äººå·¥è¯„ä¼°çš„ä¸€è‡´æ€§
            # å¦‚æœè‡ªåŠ¨åŒ–è¯„ä¼°ä¸ºé«˜åˆ†ä¸”äººå·¥è¯„ä¼°ä¸ºå‡†ç¡®ï¼Œæˆ–è‡ªåŠ¨åŒ–è¯„ä¼°ä¸ºä½åˆ†ä¸”äººå·¥è¯„ä¼°ä¸ºä¸å‡†ç¡®ï¼Œåˆ™è®¤ä¸ºä¸€è‡´
            consistent_count = 0
            for r in results:
                if r['accuracy']:
                    if (r['auto_score'] >= 0.7 and r['accuracy'] == 'high') or \
                       (r['auto_score'] < 0.5 and r['accuracy'] == 'low'):
                        consistent_count += 1
            
            consistency_pct = (consistent_count / total_rated * 100) if total_rated > 0 else 0
            print("ğŸ“Š æ€»ä½“ä¸€è‡´æ€§:")
            print(f"  è‡ªåŠ¨åŒ–è¯„ä¼°ä¸äººå·¥è¯„ä¼°ä¸€è‡´: {consistent_count}/{total_rated} ({consistency_pct:.1f}%)")
            print()
    
    # å»ºè®®
    print("ğŸ’¡ ä¸»è¦å‘ç°:")
    if expression_bias_count > 0:
        print(f"  - å‘ç° {expression_bias_count} ä¸ªFAQå­˜åœ¨è¡¨è¾¾åå·®ï¼Œè¯å®äº†QAFactEvalçš„å±€é™æ€§")
    if low_auto_accurate_pct > 20:
        print(f"  - ä½åˆ†FAQä¸­æœ‰ {low_auto_accurate_pct:.1f}% å®é™…æ˜¯å‡†ç¡®çš„ï¼Œè¡¨æ˜å­˜åœ¨è¯„ä¼°åå·®")
    if high_auto_accurate_pct < 80:
        print(f"  - é«˜åˆ†FAQä¸­åªæœ‰ {high_auto_accurate_pct:.1f}% è¢«ç¡®è®¤ä¸ºå‡†ç¡®ï¼Œå¯èƒ½éœ€è¦è°ƒæ•´è¯„ä¼°é˜ˆå€¼")
    print()

def main():
    """ä¸»å‡½æ•°"""
    import sys
    
    # é»˜è®¤ä½¿ç”¨å¡«å†™å¥½çš„æ–‡æ¡£
    filename = "manual_verification_samples_filled.md"
    if len(sys.argv) > 1:
        filename = sys.argv[1]
    
    print("æ­£åœ¨è§£æéªŒè¯æ–‡æ¡£...")
    try:
        results = parse_verification_document(filename)
        analyze_results(results)
    except FileNotFoundError:
        print(f"âŒ æœªæ‰¾åˆ°éªŒè¯æ–‡æ¡£: {filename}")
        print("   è¯·å…ˆè¿è¡Œ: python generate_verification_results.py")
    except Exception as e:
        print(f"âŒ è§£æé”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()

