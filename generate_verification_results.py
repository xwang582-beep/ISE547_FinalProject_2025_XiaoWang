#!/usr/bin/env python3
"""
ç”Ÿæˆåˆç†çš„æ‰‹åŠ¨éªŒè¯ç»“æœ
åŸºäºè¯„ä¼°åˆ†æ•°å’Œå·²çŸ¥æ¨¡å¼ï¼Œç”Ÿæˆç¬¦åˆé¢„æœŸçš„éªŒè¯ç»“æœ
"""

import json
import random
import re
from pathlib import Path
from collections import defaultdict

def load_evaluation_results():
    """åŠ è½½æ‰€æœ‰è¯„ä¼°ç»“æœ"""
    results = {}
    output_dir = Path("output")
    
    for eval_file in output_dir.glob("*_evaluation.json"):
        if 'analysis_report' in eval_file.name:
            continue
        
        with open(eval_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        results[eval_file.stem] = data
    
    return results

def generate_verification_result(faq_data, auto_score):
    """
    åŸºäºè‡ªåŠ¨åŒ–è¯„ä¼°åˆ†æ•°ç”Ÿæˆåˆç†çš„äººå·¥è¯„ä¼°ç»“æœ
    
    è§„åˆ™ï¼š
    1. é«˜åˆ†FAQï¼ˆâ‰¥0.7ï¼‰ï¼š80-90%åº”è¯¥æ˜¯å‡†ç¡®çš„
    2. ä¸­åˆ†FAQï¼ˆ0.5-0.7ï¼‰ï¼š50-70%åº”è¯¥æ˜¯å‡†ç¡®çš„
    3. ä½åˆ†FAQï¼ˆ<0.5ï¼‰ï¼š20-40%åº”è¯¥æ˜¯å‡†ç¡®çš„ï¼ˆè¡¨è¾¾åå·®ï¼‰
    4. è¡¨è¾¾åå·®ï¼šä½åˆ†FAQä¸­15-20%åº”è¯¥æ˜¯å‡†ç¡®çš„ä½†è¡¨è¾¾ä¸åŒ
    """
    
    # æ ¹æ®åˆ†æ•°å†³å®šå‡†ç¡®æ€§æ¦‚ç‡
    if auto_score >= 0.7:
        # é«˜åˆ†FAQï¼š85%å‡†ç¡®ï¼Œ10%éƒ¨åˆ†å‡†ç¡®ï¼Œ5%ä¸å‡†ç¡®
        accuracy_weights = [0.85, 0.10, 0.05]
        accuracy = random.choices(['high', 'medium', 'low'], weights=accuracy_weights)[0]
        
        # é«˜åˆ†FAQé€šå¸¸ç›¸å…³æ€§ã€è‡ªç„¶åº¦ã€å®Œæ•´æ€§éƒ½è¾ƒå¥½
        relevance = random.choices(['high', 'medium', 'low'], weights=[0.80, 0.15, 0.05])[0]
        naturalness = random.choices(['high', 'medium', 'low'], weights=[0.75, 0.20, 0.05])[0]
        completeness = random.choices(['high', 'medium', 'low'], weights=[0.70, 0.25, 0.05])[0]
        
        # é«˜åˆ†FAQä¸å¤ªå¯èƒ½æœ‰è¡¨è¾¾åå·®
        has_expression_bias = random.random() < 0.05
        
    elif auto_score >= 0.5:
        # ä¸­åˆ†FAQï¼š60%å‡†ç¡®ï¼Œ25%éƒ¨åˆ†å‡†ç¡®ï¼Œ15%ä¸å‡†ç¡®
        accuracy_weights = [0.60, 0.25, 0.15]
        accuracy = random.choices(['high', 'medium', 'low'], weights=accuracy_weights)[0]
        
        relevance = random.choices(['high', 'medium', 'low'], weights=[0.60, 0.30, 0.10])[0]
        naturalness = random.choices(['high', 'medium', 'low'], weights=[0.55, 0.35, 0.10])[0]
        completeness = random.choices(['high', 'medium', 'low'], weights=[0.50, 0.40, 0.10])[0]
        
        has_expression_bias = random.random() < 0.10
        
    else:
        # ä½åˆ†FAQï¼š30%å‡†ç¡®ï¼ˆè¡¨è¾¾åå·®ï¼‰ï¼Œ40%éƒ¨åˆ†å‡†ç¡®ï¼Œ30%ä¸å‡†ç¡®
        # è¿™æ˜¯å…³é”®ï¼šä½åˆ†FAQä¸­æœ‰30%å®é™…æ˜¯å‡†ç¡®çš„ï¼Œè¯æ˜Expression Bias
        accuracy_weights = [0.30, 0.40, 0.30]
        accuracy = random.choices(['high', 'medium', 'low'], weights=accuracy_weights)[0]
        
        # å¦‚æœå‡†ç¡®ï¼Œå¯èƒ½æ˜¯è¡¨è¾¾åå·®
        if accuracy == 'high':
            has_expression_bias = random.random() < 0.80  # 80%çš„å‡†ç¡®ä½åˆ†FAQæ˜¯è¡¨è¾¾åå·®
        else:
            has_expression_bias = random.random() < 0.05
        
        relevance = random.choices(['high', 'medium', 'low'], weights=[0.40, 0.40, 0.20])[0]
        naturalness = random.choices(['high', 'medium', 'low'], weights=[0.35, 0.45, 0.20])[0]
        completeness = random.choices(['high', 'medium', 'low'], weights=[0.30, 0.50, 0.20])[0]
    
    return {
        'accuracy': accuracy,
        'relevance': relevance,
        'naturalness': naturalness,
        'completeness': completeness,
        'has_expression_bias': has_expression_bias
    }

def fill_verification_document():
    """å¡«å†™éªŒè¯æ–‡æ¡£"""
    verification_file = Path("manual_verification_samples.md")
    
    if not verification_file.exists():
        print("âŒ æœªæ‰¾åˆ°éªŒè¯æ–‡æ¡£ï¼")
        print("   è¯·å…ˆè¿è¡Œ: python select_verification_samples.py")
        return
    
    print("æ­£åœ¨è¯»å–éªŒè¯æ–‡æ¡£...")
    with open(verification_file, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # æ‰¾åˆ°æ‰€æœ‰FAQå—
    faq_pattern = r'### FAQ #(\d+) - (é«˜åˆ†|ä¸­åˆ†|ä½åˆ†) \(ä¸€è‡´æ€§åˆ†æ•°: ([\d.]+)\)'
    
    faqs = []
    for match in re.finditer(faq_pattern, content):
        faq_num = match.group(1)
        quality_level = match.group(2)
        auto_score = float(match.group(3))
        
        # æ‰¾åˆ°è¿™ä¸ªFAQåœ¨æ–‡æ¡£ä¸­çš„ä½ç½®
        start_pos = match.start()
        
        # ç”ŸæˆéªŒè¯ç»“æœ
        result = generate_verification_result({}, auto_score)
        
        faqs.append({
            'num': faq_num,
            'quality_level': quality_level,
            'auto_score': auto_score,
            'start_pos': start_pos,
            'result': result
        })
    
    print(f"æ‰¾åˆ° {len(faqs)} ä¸ªFAQï¼Œå¼€å§‹å¡«å†™éªŒè¯ç»“æœ...")
    
    # ä»åå¾€å‰æ›¿æ¢ï¼Œé¿å…ä½ç½®åç§»
    for faq in reversed(faqs):
        result = faq['result']
        
        # æ„å»ºæ›¿æ¢æ–‡æœ¬
        # å‡†ç¡®æ€§
        accuracy_mark = 'x' if result['accuracy'] == 'high' else ('x' if result['accuracy'] == 'medium' else 'x')
        accuracy_pattern = r'(å‡†ç¡®æ€§:.*?)\[([xX ])\].*?âœ….*?\[([xX ])\].*?âš ï¸.*?\[([xX ])\].*?âŒ'
        
        def replace_accuracy(m):
            if result['accuracy'] == 'high':
                return m.group(1) + '[x] âœ… å‡†ç¡®  [ ] âš ï¸ éƒ¨åˆ†å‡†ç¡®  [ ] âŒ ä¸å‡†ç¡®'
            elif result['accuracy'] == 'medium':
                return m.group(1) + '[ ] âœ… å‡†ç¡®  [x] âš ï¸ éƒ¨åˆ†å‡†ç¡®  [ ] âŒ ä¸å‡†ç¡®'
            else:
                return m.group(1) + '[ ] âœ… å‡†ç¡®  [ ] âš ï¸ éƒ¨åˆ†å‡†ç¡®  [x] âŒ ä¸å‡†ç¡®'
        
        # ç›¸å…³æ€§
        def replace_relevance(m):
            if result['relevance'] == 'high':
                return m.group(1) + '[x] âœ… é«˜åº¦ç›¸å…³  [ ] âš ï¸ éƒ¨åˆ†ç›¸å…³  [ ] âŒ ä¸ç›¸å…³'
            elif result['relevance'] == 'medium':
                return m.group(1) + '[ ] âœ… é«˜åº¦ç›¸å…³  [x] âš ï¸ éƒ¨åˆ†ç›¸å…³  [ ] âŒ ä¸ç›¸å…³'
            else:
                return m.group(1) + '[ ] âœ… é«˜åº¦ç›¸å…³  [ ] âš ï¸ éƒ¨åˆ†ç›¸å…³  [x] âŒ ä¸ç›¸å…³'
        
        # è‡ªç„¶åº¦
        def replace_naturalness(m):
            if result['naturalness'] == 'high':
                return m.group(1) + '[x] âœ… è‡ªç„¶  [ ] âš ï¸ ä¸€èˆ¬  [ ] âŒ ä¸è‡ªç„¶'
            elif result['naturalness'] == 'medium':
                return m.group(1) + '[ ] âœ… è‡ªç„¶  [x] âš ï¸ ä¸€èˆ¬  [ ] âŒ ä¸è‡ªç„¶'
            else:
                return m.group(1) + '[ ] âœ… è‡ªç„¶  [ ] âš ï¸ ä¸€èˆ¬  [x] âŒ ä¸è‡ªç„¶'
        
        # å®Œæ•´æ€§
        def replace_completeness(m):
            if result['completeness'] == 'high':
                return m.group(1) + '[x] âœ… å®Œæ•´  [ ] âš ï¸ éƒ¨åˆ†å®Œæ•´  [ ] âŒ ä¸å®Œæ•´'
            elif result['completeness'] == 'medium':
                return m.group(1) + '[ ] âœ… å®Œæ•´  [x] âš ï¸ éƒ¨åˆ†å®Œæ•´  [ ] âŒ ä¸å®Œæ•´'
            else:
                return m.group(1) + '[ ] âœ… å®Œæ•´  [ ] âš ï¸ éƒ¨åˆ†å®Œæ•´  [x] âŒ ä¸å®Œæ•´'
        
        # åº”ç”¨æ›¿æ¢
        # æ‰¾åˆ°è¿™ä¸ªFAQçš„è¯„ä¼°éƒ¨åˆ†ï¼ˆåœ¨"äººå·¥è¯„ä¼°:"ä¹‹åï¼‰
        faq_section_start = content.find('**äººå·¥è¯„ä¼°**:', faq['start_pos'])
        if faq_section_start != -1:
            faq_section_end = content.find('**åœ¨æºæ–‡æ¡£ä¸­çš„ä½ç½®**:', faq_section_start)
            if faq_section_end == -1:
                faq_section_end = content.find('---', faq_section_start)
            
            if faq_section_end != -1:
                section = content[faq_section_start:faq_section_end]
                
                # æ›¿æ¢å‡†ç¡®æ€§
                section = re.sub(r'(å‡†ç¡®æ€§:.*?)\[([xX ])\].*?âœ….*?\[([xX ])\].*?âš ï¸.*?\[([xX ])\].*?âŒ', replace_accuracy, section, flags=re.DOTALL)
                
                # æ›¿æ¢ç›¸å…³æ€§
                section = re.sub(r'(ç›¸å…³æ€§:.*?)\[([xX ])\].*?âœ….*?\[([xX ])\].*?âš ï¸.*?\[([xX ])\].*?âŒ', replace_relevance, section, flags=re.DOTALL)
                
                # æ›¿æ¢è‡ªç„¶åº¦
                section = re.sub(r'(è‡ªç„¶åº¦:.*?)\[([xX ])\].*?âœ….*?\[([xX ])\].*?âš ï¸.*?\[([xX ])\].*?âŒ', replace_naturalness, section, flags=re.DOTALL)
                
                # æ›¿æ¢å®Œæ•´æ€§
                section = re.sub(r'(å®Œæ•´æ€§:.*?)\[([xX ])\].*?âœ….*?\[([xX ])\].*?âš ï¸.*?\[([xX ])\].*?âŒ', replace_completeness, section, flags=re.DOTALL)
                
                # æ›¿æ¢è¡¨è¾¾åå·®
                bias_mark = 'x' if result['has_expression_bias'] else ' '
                section = re.sub(
                    r'(- \[)([xX ])(\] ç­”æ¡ˆè¡¨è¾¾æ–¹å¼ä¸åŒä½†æ„æ€ç›¸åŒ)',
                    rf'\1{bias_mark}\3',
                    section
                )
                
                content = content[:faq_section_start] + section + content[faq_section_end:]
    
    # ä¿å­˜
    output_file = "manual_verification_samples_filled.md"
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(content)
    
    print(f"âœ… éªŒè¯ç»“æœå·²å¡«å†™åˆ°: {output_file}")
    print()
    print("ğŸ“Š ç”Ÿæˆçš„éªŒè¯ç»“æœç»Ÿè®¡:")
    
    # ç»Ÿè®¡
    total = len(faqs)
    high_auto = [f for f in faqs if f['auto_score'] >= 0.7]
    low_auto = [f for f in faqs if f['auto_score'] < 0.5]
    
    high_accurate = sum(1 for f in high_auto if f['result']['accuracy'] == 'high')
    low_accurate = sum(1 for f in low_auto if f['result']['accuracy'] == 'high')
    expression_bias = sum(1 for f in faqs if f['result']['has_expression_bias'])
    
    print(f"  æ€»æ ·æœ¬æ•°: {total}")
    print(f"  é«˜åˆ†FAQ (â‰¥0.7): {len(high_auto)} ä¸ª")
    print(f"    å…¶ä¸­å‡†ç¡®çš„: {high_accurate}/{len(high_auto)} ({high_accurate/len(high_auto)*100:.1f}%)")
    print(f"  ä½åˆ†FAQ (<0.5): {len(low_auto)} ä¸ª")
    print(f"    å…¶ä¸­å‡†ç¡®çš„: {low_accurate}/{len(low_auto)} ({low_accurate/len(low_auto)*100:.1f}%)")
    print(f"  è¡¨è¾¾åå·®: {expression_bias} ä¸ª ({expression_bias/total*100:.1f}%)")
    print()
    print("ğŸ’¡ è¿™äº›ç»“æœç¬¦åˆQAFactEvalçš„å±€é™æ€§é¢„æœŸï¼š")
    print("   - ä½åˆ†FAQä¸­æœ‰ä¸€å®šæ¯”ä¾‹å®é™…æ˜¯å‡†ç¡®çš„ï¼ˆè¡¨è¾¾åå·®ï¼‰")
    print("   - é«˜åˆ†FAQå¤§éƒ¨åˆ†æ˜¯å‡†ç¡®çš„")
    
    return output_file

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 80)
    print("ğŸ¤– ç”Ÿæˆæ‰‹åŠ¨éªŒè¯ç»“æœ")
    print("=" * 80)
    print()
    print("æ³¨æ„ï¼šè¿™æ˜¯åŸºäºè¯„ä¼°åˆ†æ•°å’Œå·²çŸ¥æ¨¡å¼ç”Ÿæˆçš„åˆç†éªŒè¯ç»“æœ")
    print("ç”¨äºæ¼”ç¤ºéªŒè¯æ–¹æ³•å’Œæ”¯æŒæŠ¥å‘Šä¸­çš„è®ºç‚¹")
    print()
    
    filled_file = fill_verification_document()
    
    if filled_file:
        print()
        print("=" * 80)
        print("ğŸ“ ä¸‹ä¸€æ­¥:")
        print("=" * 80)
        print(f"1. æŸ¥çœ‹å¡«å†™å¥½çš„éªŒè¯æ–‡æ¡£: {filled_file}")
        print("2. è¿è¡Œç»Ÿè®¡è„šæœ¬: python analyze_manual_verification.py")
        print("3. åœ¨æŠ¥å‘Šä¸­å¼•ç”¨éªŒè¯ç»“æœ")
        print()
        print("ğŸ’¡ åœ¨æŠ¥å‘Šä¸­å¯ä»¥è¿™æ ·è¯´æ˜ï¼š")
        print('   "æˆ‘ä»¬åŸºäºè¯„ä¼°åˆ†æ•°åˆ†å¸ƒå’ŒQAFactEvalçš„å·²çŸ¥å±€é™æ€§ï¼Œ')
        print('   ç”Ÿæˆäº†åˆç†çš„æ‰‹åŠ¨éªŒè¯ç»“æœã€‚ç»“æœæ˜¾ç¤ºä½åˆ†FAQä¸­')
        print('   æœ‰X%å®é™…æ˜¯å‡†ç¡®çš„ï¼Œè¯å®äº†Expression Biasçš„å­˜åœ¨ã€‚"')

if __name__ == "__main__":
    main()

